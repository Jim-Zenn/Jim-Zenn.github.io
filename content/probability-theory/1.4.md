---
title: "Total Probability Theorem and Bayes' Rule"
date: 2018-06-29T9:03:48+08:00
volumes: ["1"]
layout: "note"
issue: 4
weight: 14

---


<!--more-->

<div class="latex-macros">
  {{< raw >}}
    $\newcommand{\br}{\\}$

    $\newcommand{\R}{\mathbb{R}}$
    $\newcommand{\Q}{\mathbb{Q}}$
    $\newcommand{\Z}{\mathbb{Z}}$
    $\newcommand{\N}{\mathbb{N}}$
    $\newcommand{\C}{\mathbb{C}}$
    $\newcommand{\P}{\mathbb{P}}$
    $\newcommand{\F}{\mathbb{F}}$
    $\newcommand{\L}{\mathcal{L}}$
    $\newcommand{\spa}[1]{\text{span}(#1)}$
    $\newcommand{\set}[1]{\{#1\}}$
    $\newcommand{\emptyset}{\varnothing}$
    $\newcommand{\otherwise}{\text{ otherwise }}$
    $\newcommand{\if}{\text{ if }}$
    $\newcommand{\union}{\cup}$
    $\newcommand{\intercept}{\cap}$
    $\newcommand{\abs}[1]{| #1 |}$
    $\newcommand{\pare}[1]{\left\(#1\right\)}$
    $\newcommand{\t}[1]{\text{ #1 }}$
    $\newcommand{\head}{\text H}$
    $\newcommand{\tail}{\text T}$
    $\newcommand{\inv}[1]{{#1}^{-1}}$
    $\newcommand{\nullity}[1]{\text{nullity}(#1)}$
    $\newcommand{\rank}[1]{\text{rank }#1}$
    $\newcommand{\oto}{\text{ one-to-one }}$
    $\newcommand{\ot}{\text{ onto }}$


    $\newcommand{\Vcw}[2]{\begin{bmatrix} #1 \br #2 \end{bmatrix}}$
    $\newcommand{\Vce}[3]{\begin{bmatrix} #1 \br #2 \br #3 \end{bmatrix}}$
    $\newcommand{\Vcr}[4]{\begin{bmatrix} #1 \br #2 \br #3 \br #4 \end{bmatrix}}$
    $\newcommand{\Vct}[5]{\begin{bmatrix} #1 \br #2 \br #3 \br #4 \br #5 \end{bmatrix}}$
    $\newcommand{\Vcy}[6]{\begin{bmatrix} #1 \br #2 \br #3 \br #4 \br #5 \br #6 \end{bmatrix}}$
    $\newcommand{\Vcu}[7]{\begin{bmatrix} #1 \br #2 \br #3 \br #4 \br #5 \br #6 \br #7 \end{bmatrix}}$

    $\newcommand{\Mqw}[2]{\begin{bmatrix} #1 & #2 \end{bmatrix}}$
    $\newcommand{\Mqe}[3]{\begin{bmatrix} #1 & #2 & #3 \end{bmatrix}}$
    $\newcommand{\Mqr}[4]{\begin{bmatrix} #1 & #2 & #3 & #4 \end{bmatrix}}$
    $\newcommand{\Mqt}[5]{\begin{bmatrix} #1 & #2 & #3 & #4 & #5 \end{bmatrix}}$

    $\newcommand{\Mwq}[2]{\begin{bmatrix} #1 \br #2 \end{bmatrix}}$
    $\newcommand{\Meq}[3]{\begin{bmatrix} #1 \br #2 \br #3 \end{bmatrix}}$
    $\newcommand{\Mrq}[4]{\begin{bmatrix} #1 \br #2 \br #3 \br #4 \end{bmatrix}}$
    $\newcommand{\Mtq}[5]{\begin{bmatrix} #1 \br #2 \br #3 \br #4 \br #5 \end{bmatrix}}$

    $\newcommand{\Mqw}[2]{\begin{bmatrix} #1 & #2 \end{bmatrix}}$
    $\newcommand{\Mwq}[2]{\begin{bmatrix} #1 \br #2 \end{bmatrix}}$
    $\newcommand{\Mww}[4]{\begin{bmatrix} #1 & #2 \br #3 & #4 \end{bmatrix}}$
    $\newcommand{\Mqe}[3]{\begin{bmatrix} #1 & #2 & #3 \end{bmatrix}}$
    $\newcommand{\Meq}[3]{\begin{bmatrix} #1 \br #2 \br #3 \end{bmatrix}}$
    $\newcommand{\Mwe}[6]{\begin{bmatrix} #1 & #2 & #3\br #4 & #5 & #6 \end{bmatrix}}$
    $\newcommand{\Mew}[6]{\begin{bmatrix} #1 & #2 \br #3 & #4 \br #5 & #6 \end{bmatrix}}$
    $\newcommand{\Mee}[9]{\begin{bmatrix} #1 & #2 & #3 \br #4 & #5 & #6 \br #7 & #8 & #9 \end{bmatrix}}$
  {{< /raw >}}
</div>

{{% theorem name=" Simplified version of Total Probability Theorem" %}}

let $B \subset \Omega$, for any event $A$ , $A\cap B$ and $A\cap B^c$ are **disjoint**. $$P(A) = P(A\cap B) + P(A\cap B^c)=P(A|B)P(B)+P(A|B^c)P(B^c)$$

{{% /theorem %}}

{{% example name="yogurt" %}}

At the store there are two flavours of yogurt, apple and berry. There are 100 Apple yogurts and 20% of which are expired; there are 200 Berry yogurts and 10% of which are expired.
<br>
I choose a yogurt at random. What's the chance that it's expired?

Let $E$ denote the event that yogurt I get is expired. <br>
Let $A$ and $B$ respectively denote the events that I get Apple or Berry yogurt.

$P(E) = P(E|A)P(A)+P(E|B)P(B)=P(E|A)P(A)+P(E|A^c)P(A^c)$

$=20\%\times\frac{100}{300}+10\%\times\frac{200}{300}$

$=\frac{2}{15}$

{{% /example %}}


{{% example name="yogurt2" %}}

A different store has same selection of apple and berry (same \% are expired) plus 300 Cherry yogurts, 5% of which are expired.

$P(E) = P(E|A)P(A)+P(E|B)P(B)+ P(E|C)P(C)$

$=20\%\times\frac{100}{600}+10\%\times\frac{200}{600}+5\%\times\frac{300}{600}$

$=\frac{11}{120}$



{{% /example %}}

{{% definition name="Partition" %}}

We say $B\_1, B\_2...$, are partitions of $\Omega,$ if $B\_i \cap B\_j = \emptyset$ for $ i\neq j$ and $\underset i \cup B\_i = \Omega$.

{{% /definition %}}

 {{% theorem name=" Total Probability Theorem" %}}

If $B\_1,B\_2,... $ partitions $\Omega$ and $A\subset \Omega$, then  A = $\underset i \cup(A\cap B\_i)$ and this is a disjoint union. Thus,
$$P(A) = \underset i \Sigma P(A|B\_i)P(B\_i)$$

 {{% /theorem %}}

{{% example name="Stack of Cards" %}}

Standard deck of 52 cards (4 suits, each suite has 13 cards, 2-10, J, Q, K, A).

> I draw a card at random.

$P(\text{not a heart}) = \frac34$

> Draw 2 cards (without replacement). $P(\text{neither is a heart}) = ?$

let $A\_i$ be the event that $i$th card is not a heart.

$P(\text{neither is a heart}) = P(A\_1\cap A\_2)$

$P(A\_1\cap A\_2)=P(A\_2 | A\_1)P(A\_1)= \frac{38}{51}\times \frac{39}{52}$

$P(A\_1\cap A\_2\cap A\_3) =?$

In general, let $B\_1, B\_2, ..., B\_n$ be events of positive probability. Note the telescoping product:

$P(\underset {i=1}{\overset n \cap} B\_i)=P(B\_1)\frac{P(B\_1\cap B\_2)}{P(B\_1)}\frac{P(B\_1\cap B\_2 \cap B\_3)}{P(B\_1\cap B\_2)}...\frac{P(\underset {i=1}{\overset n \cap} B\_i)}{P(\underset {i=1}{\overset {n-1} \cap} B\_i)}$

$P(\underset {i=1}{\overset n \cap} B\_i)=P(B\_1)P(B\_2|B\_1)P(B\_3|B\_1\cap B\_2)...P(B\_n|\underset {i=1}{\overset {n-1} \cap} B\_i)$

$P(A\_1\cap A\_2\cap A\_3) =P(A\_1)\cdot P(A\_2|A\_1)\cdot P(A\_3|A\_1 \cap A\_2)=\frac{39}{52}\cdot \frac{38}{51} \cdot \frac{37}{50}$

{{% /example %}}

# Inference

We have $A\_1, ..., A\_n$ underlying causes, i.e. events that form a partition of $\Omega$, and an "effect" or "observation" $B \subset \Omega$. I know $P(B|A\_i)$, $i= 1, ... ,n$.

Want to know if I observe a $B$, how likely is it that $A\_i$ was the cause?

I know $P(A\_i)$ for $i=1,2,...,n$

Then $P(A\_j|B)=\frac{P(A\_j \cap B)}{P(B)}=\frac{P(B|A\_j)P(A\_j)}{P(B)}$

since $A\_1, ..., A\_n$ partition $\Omega$, $P(B)=\underset {i=1}{\overset {n} \Sigma} P(B|A\_i)P(A\_i),$

{{% theorem name="Bayes Rule" %}}

Let $A\_1 , A\_2, ..., A\_n$ be disjoint events that form a partition of the sample space, and assume that $P(A\_i) > 0, \forall i$. Then, for any event $B$ such that $P(B) > 0$, we have

$$P(A|B)= \frac{P(B|A\_j)P(A\_j)}{\underset {i=1}{\overset {n} \Sigma} P(B|A\_i)P(A\_i)}$$

{{% /theorem %}}

{{% example name="2 coins" %}}

We have 2 coins, coin 1 shows H with probability $90\%$, coin 2 shows H with probability $5\%$. They look the same. I pick one at random & toss it shows H. Chance it is coin 1?

"causes": picking the coin. Let $A\_1$ be event I got coin 1, $A\_2$ be event I got coin 2.

$B$ is event I got H tossing. seek $P(A\_1|B)$.

Using Bayes rule,

$P(A\_1|B)=\frac{P(B|A\_1)P(A\_1)}{P(B)}=\frac{P(B|A\_1)P(A\_1)}{P(B|A\_1)P(A\_1)+P(B|A\_2)P(A\_2)}=\frac{90\%\times\frac12}{90\%\times\frac12+5\%\frac12}=\frac{18}{19}$

{{% /example %}}

{{% example name="Disease" %}}
Some scientists design a test for a disease. The disease occurs 0.1% of the population. If the person has disease, test identifies 95% of the time; if the person has no disease, test gives negative result 95% of the time. Question: if a person picked at random from population tests positive, how likely is it that they have the disease?

Setup:
Let $A$ be the event that person has the disease.
Note: $A$ & $A^c$ are a partition.
Let $B$ be the event that the person test positive.
We seek $P(A|B)$ by Bayes' Law.

$$
\begin{align\*}
P(A|B) &= \frac{P(B|A)P(A)}{P(B|A)P(A) + P(B|A^c)P(A^c)} \br
&= \frac{0.95\times 0.001}{0.95\times 0.001 + 0.05 \times 0.999} \br
&= 0.0187 = 1.8\%
\end{align*}
$$

{{% /example %}}

Sometimes we want to capture idea that "knowing that $B \subset \Omega$ occrued gives no info about whether $A$ occured, \& vice versa". If this is the case, we think $P(A|B)=P(A).$ A more formal definition:
