---
title: "Probabilistic Models"
date: 2018-06-27T9:03:48+08:00
volumes: ["1"]
layout: "note"
issue: 2
weight: 12

---


<!--more-->

<div class="latex-macros">
  {{< raw >}}
    $\newcommand{\br}{\\}$

    $\newcommand{\R}{\mathbb{R}}$
    $\newcommand{\Q}{\mathbb{Q}}$
    $\newcommand{\Z}{\mathbb{Z}}$
    $\newcommand{\N}{\mathbb{N}}$
    $\newcommand{\C}{\mathbb{C}}$
    $\newcommand{\P}{\mathbb{P}}$
    $\newcommand{\F}{\mathbb{F}}$
    $\newcommand{\L}{\mathcal{L}}$
    $\newcommand{\spa}[1]{\text{span}(#1)}$
    $\newcommand{\dist}[1]{\text{dist}(#1)}$
    $\newcommand{\max}[1]{\text{max}(#1)}$
    $\newcommand{\min}[1]{\text{max}(#1)}$
    $\newcommand{\supr}[1]{\text{sup}(#1)}$
    $\newcommand{\infi}[1]{\text{inf}(#1)}$
    $\newcommand{\argmax}[1]{\underset{#1}{\text{argmax }}}$
    $\newcommand{\argmin}[1]{\underset{#1}{\text{argmin }}}$
    $\newcommand{\set}[1]{\left\{#1\right\}}$
    $\newcommand{\emptyset}{\varnothing}$
    $\newcommand{\otherwise}{\text{ otherwise }}$
    $\newcommand{\if}{\text{ if }}$
    $\newcommand{\proj}{\text{proj}}$
    $\newcommand{\union}{\cup}$
    $\newcommand{\intercept}{\cap}$
    $\newcommand{\abs}[1]{\left| #1 \right|}$
    $\newcommand{\norm}[1]{\left\lVert#1\right\rVert}$
    $\newcommand{\pare}[1]{\left(#1\right)}$
    $\newcommand{\t}[1]{\text{ #1 }}$
    $\newcommand{\head}{\text H}$
    $\newcommand{\tail}{\text T}$
    $\newcommand{\d}{\text d}$
    $\newcommand{\limu}[2]{\underset{#1 \to #2}\lim}$
    $\newcommand{\der}[2]{\frac{\d #1}{\d #2}}$
    $\newcommand{\derw}[2]{\frac{\d #1^2}{\d^2 #2}}$
    $\newcommand{\pder}[2]{\frac{\partial #1}{\partial #2}}$
    $\newcommand{\pderw}[2]{\frac{\partial^2 #1}{\partial #2^2}}$
    $\newcommand{\pderws}[3]{\frac{\partial^2 #1}{\partial #2 \partial #3}}$
    $\newcommand{\inv}[1]{{#1}^{-1}}$
    $\newcommand{\inner}[2]{\langle #1, #2 \rangle}$
    $\newcommand{\nullity}[1]{\text{nullity}(#1)}$
    $\newcommand{\rank}[1]{\text{rank }#1}$
    $\newcommand{\nullspace}[1]{\mathcal{N}\pare{#1}}$
    $\newcommand{\range}[1]{\mathcal{R}\pare{#1}}$
    $\newcommand{\var}[1]{\text{var}(#1)}$
    $\newcommand{\tr}[1]{\text{tr}(#1)}$
    $\newcommand{\oto}{\text{ one-to-one }}$
    $\newcommand{\ot}{\text{ onto }}$
    $\newcommand{\ceil}[1]{\lceil#1\rceil}$
    $\newcommand{\floor}[1]{\lfloor#1\rfloor}$
    $\newcommand{\Re}[1]{\text{Re}(#1)}$
    $\newcommand{\Im}[1]{\text{Im}(#1)}$
    $\newcommand{\dom}[1]{\text{dom}(#1)}$
    $\newcommand{\fnext}[1]{\overset{\sim}{#1}}$
    $\newcommand{\transpose}[1]{{#1}^{\text{T}}}$
    $\newcommand{\b}[1]{\boldsymbol{#1}}$
    $\newcommand{\None}[1]{}$


    $\newcommand{\Vcw}[2]{\begin{bmatrix} #1 \br #2 \end{bmatrix}}$
    $\newcommand{\Vce}[3]{\begin{bmatrix} #1 \br #2 \br #3 \end{bmatrix}}$
    $\newcommand{\Vcr}[4]{\begin{bmatrix} #1 \br #2 \br #3 \br #4 \end{bmatrix}}$
    $\newcommand{\Vct}[5]{\begin{bmatrix} #1 \br #2 \br #3 \br #4 \br #5 \end{bmatrix}}$
    $\newcommand{\Vcy}[6]{\begin{bmatrix} #1 \br #2 \br #3 \br #4 \br #5 \br #6 \end{bmatrix}}$
    $\newcommand{\Vcu}[7]{\begin{bmatrix} #1 \br #2 \br #3 \br #4 \br #5 \br #6 \br #7 \end{bmatrix}}$

    $\newcommand{\vcw}[2]{\begin{matrix} #1 \br #2 \end{matrix}}$
    $\newcommand{\vce}[3]{\begin{matrix} #1 \br #2 \br #3 \end{matrix}}$
    $\newcommand{\vcr}[4]{\begin{matrix} #1 \br #2 \br #3 \br #4 \end{matrix}}$
    $\newcommand{\vct}[5]{\begin{matrix} #1 \br #2 \br #3 \br #4 \br #5 \end{matrix}}$
    $\newcommand{\vcy}[6]{\begin{matrix} #1 \br #2 \br #3 \br #4 \br #5 \br #6 \end{matrix}}$
    $\newcommand{\vcu}[7]{\begin{matrix} #1 \br #2 \br #3 \br #4 \br #5 \br #6 \br #7 \end{matrix}}$

    $\newcommand{\Mqw}[2]{\begin{bmatrix} #1 & #2 \end{bmatrix}}$
    $\newcommand{\Mqe}[3]{\begin{bmatrix} #1 & #2 & #3 \end{bmatrix}}$
    $\newcommand{\Mqr}[4]{\begin{bmatrix} #1 & #2 & #3 & #4 \end{bmatrix}}$
    $\newcommand{\Mqt}[5]{\begin{bmatrix} #1 & #2 & #3 & #4 & #5 \end{bmatrix}}$

    $\newcommand{\Mwq}[2]{\begin{bmatrix} #1 \br #2 \end{bmatrix}}$
    $\newcommand{\Meq}[3]{\begin{bmatrix} #1 \br #2 \br #3 \end{bmatrix}}$
    $\newcommand{\Mrq}[4]{\begin{bmatrix} #1 \br #2 \br #3 \br #4 \end{bmatrix}}$
    $\newcommand{\Mtq}[5]{\begin{bmatrix} #1 \br #2 \br #3 \br #4 \br #5 \end{bmatrix}}$

    $\newcommand{\Mqw}[2]{\begin{bmatrix} #1 & #2 \end{bmatrix}}$
    $\newcommand{\Mwq}[2]{\begin{bmatrix} #1 \br #2 \end{bmatrix}}$
    $\newcommand{\Mww}[4]{\begin{bmatrix} #1 & #2 \br #3 & #4 \end{bmatrix}}$
    $\newcommand{\Mqe}[3]{\begin{bmatrix} #1 & #2 & #3 \end{bmatrix}}$
    $\newcommand{\Meq}[3]{\begin{bmatrix} #1 \br #2 \br #3 \end{bmatrix}}$
    $\newcommand{\Mwe}[6]{\begin{bmatrix} #1 & #2 & #3\br #4 & #5 & #6 \end{bmatrix}}$
    $\newcommand{\Mew}[6]{\begin{bmatrix} #1 & #2 \br #3 & #4 \br #5 & #6 \end{bmatrix}}$
    $\newcommand{\Mee}[9]{\begin{bmatrix} #1 & #2 & #3 \br #4 & #5 & #6 \br #7 & #8 & #9 \end{bmatrix}}$
  {{< /raw >}}
</div>

{{% definition name="Probabilistic Model" %}}
A probabilistic model is a mathematical description of an uncertain situation.

A probabilistic model have two main ingredients: a **sample space** and a **probability law**.
{{% /definition %}}

{{% definition name="experiment and outcomes" status="" %}}

Every probabilistic model involves an underlying process, called the **experiment**, that will produce exactly one out of several possible **outcomes**.

{{% /definition %}}

{{% definition name="Sample Space" %}}

A **sample space** $\Omega$ is the set of all possible **outcomes** of an experiment.

A collection of possible outcomes is called an **event**.

{{% /definition %}}

{{% definition name="Probability Law" %}}

The **probability law** assigns a set $A$ of possible outcomes (also called an **event**) a nonnegative number $P(A)$(called the **probability** of $A$).

The probability law should encode our knowledge or belief about the collective "likelihood" of the elements of $A$.

{{% /definition %}}

{{% axioms name="Probability Axioms" %}}

Any probability law must satisfies the following axioms:

1. **(Nonnegativity)** $P(A)\geq 0$, for every event $A$.
2. **(Additivity)** if $A\_1,A\_2,...$ is a sequence of disjoint events, then the probability of their union satisfies $P(A\_1\cup A\_2 \cup ...)=P(A\_1) + P(A\_2)+...$.
3. **(Normalization)** $P(\Omega)=1$.

{{% /axioms %}}


To represent the experiment well, $\Omega $ must be **collectively exhaustive**, In other words, no mather what happens, all outcomes are in $\Omega$, and $\Omega$ consists only of outcomes.

{{% examples %}}

Two coin tosses $\Omega = \set{\text{HH}, \text{TH}, \text{HT}, \text{TT}}$

$\text{HH}$ is an **outcome**, $\set{\text{HH}, \text{TT}}$ is an **event** i.e. "Getting same results on both tosses".


{{% /examples %}}

{{% definition %}}

**probability law** $P$ assigns to each event $A$ a number $P(A)$. called the **probability** of A.

{{% /definition %}}


{{% examples %}}

One fair coin toss $\Omega=\set{H, T}, P(\set{H})=P(\set{T})=0.5$

{{% /examples %}}

{{% definition %}}

Two sets $A,B$ are **disjoint** if $A\cap B=\emptyset$,

{{% /definition %}}

{{% examples %}}

Describe one <u>unfair</u> coin toss where chance of $H$ is $\frac{1}{4}$.

$\Omega =\set{\text{H}, \text{T}}, P(\set{\text{H}})=\frac{1}{4}, P(\set{\text{T}})=\frac{3}{4}$

note: $P(\text{H}\cup\text{T}) = 1$

{{% /examples %}}

{{% properties name="Discrete Probability Law" %}}

If a sample space consists of a **finite** or even just **countable** number of outcomes, then the probability law is specified by the probabilities of the events that consist of a single element.

In particular, the probability of any event $\set{s\_1,s\_2,...,s\_n}$ is the sum of the probabilities of its elements:

$$P(\set{x\_1, x\_2, ..., x\_n})=P(\set{x\_1})+P(\set{x\_2})+...+P(\set{x\_n})$$

{{% /properties %}}

We denote the number of possible outcomes in a set of outcomes A as $\abs{A}$.

{{% properties name="Discrete Uniform Probability Law" %}}

If a sample space consists of $n$ possible outcomes which are equally likely, then $\forall$ event $A, $P(A) = \abs A \cdot \frac{1}{n}=\frac{\abs{A}}{\abs \Omega}$

{{% /properties %}}

{{% properties name="Properties of Probability Laws" %}}

Consider a probability law, and let $A, B$, and $C$ be events.

1. if $A \subset B$, then $P(A) \leq P(B)$.
2. $P(\emptyset)=0$
3. $P(A^c) = 1 - P(A)$
4. $P(A\cup B) = P(A) + P(B) - P(A\cap B)$
5. $A\_1 \subset A\_2 \subset ... \subset \Omega \implies P(\cup ^ \infty \_ {i = 1} A\_i) = \limu{ i }{ \infty } P(A\_i)$ <br> $\Omega \supset A\_1 \supset A\_2 \supset ...  \implies P(\cap ^ \infty \_ {i = 1} A\_i) = \limu{ i }{ \infty } P(A\_i)$


{{% proof %}}

**Properties of Probability Laws 1**

since $B=A\cup(B\cap A^C)$

$P(B) = P(A) + P(B\cap A^C) $(prbability axioms 2, Additivity)

$\geq P(A) + 0$(prbability axioms 1, Positivity)


{{% /proof %}}

{{% proof %}}
**Properties of Probability Laws 2**

$1 = P(\Omega)$     (prbability axioms 3, Normalization)

$=P(\Omega \cup \emptyset)$

$= P(\Omega) + P(\emptyset)$     (prbability axioms 1, Additivity)

$= 1 + P(\emptyset)$

$P(\emptyset) = 0$
{{% /proof %}}

{{% /properties %}}

e.g. We roll a fair 4-sided die two times

$\Omega = \set{(i, j)| i, j \in \set{1, 2, 3, 4}}$

(Grid representation) (tree representation)

Let $A$ be the event that I roll doubles

$A=\set{(i, i)| i= \set{1 ,2 ,3, 4}}$



You can use array or tree to get an idea of what's going on in a problem, but  to carefully write a solution, write sample space $\Omega$ and events $A$ as explicitly as possible.


{{% example name="Skittles" %}}

A bag of skittles contains $n$ red skittles and $n$ green skittles. Two skittles are removed at the same time (without replacement) at random. What is the probability they're different colors?

**Step 1**: write down sample space $\Omega$.

$\Omega=\set{RR, RG, GG}$ is a correct sample space. However, we cannot use this sample space design, because we cannot assign events with it.

We use $\Omega = \set{1, ..., n, n+1, ..., 2n} $

$= \set{(i,j)| i\neq j, i, j \in\set{1, ..., 2n}}$ as our sample space.

**Step 2**: In this sample space, all outcomes are equally likely.

$\abs\Omega = 2n \times (2n-1)$

$P(\text{RG})=\frac{n\cdot n}{2n(2n-1)}=P(\text{GR})$

$P(\text{diff. colors})=P(\text{RG})+P(\text{GR})$

$=\frac{n^2}{2n(2n-1)} + \frac{n^2}{2n(2n-1)} = \frac{n}{2(2n-1)}$

{{% /example %}}


{{% example name="Romeo and Juliet Have a Date" %}}

Romeo & Juliet have a date. Each will arrive between midnight and 1 am (all times are equally likely). The 1st to arrive will wait 15 minutes for the other and then leave. Probability they meet?

$\Omega = [0, 1] \times [0, 1]$

> This is an example of a model of a continuous sample space. Note $\Omega$ is uncountable. Note $P(\set{x, y}) = 0$

we interpret 'equally likely' to mean $P(A) =$ area of $A$ .

The event that represents "they meet" is $M = \set{(i, j) \in \Omega | \abs{i - j} \leq \frac{1}{4}}$

P(M) = area of M = 1/4

{{% /example %}}
