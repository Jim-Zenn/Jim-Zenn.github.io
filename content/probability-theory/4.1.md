---
title: "Derived Distributions"
date: 2018-07-25T10:34:48+08:00
volumes: ["4"]
layout: "note"
issue: 1
weight: 41

---

<!--more-->

<div class="latex-macros">
  {{< raw >}}
    $\newcommand{\br}{\\}$
    $\newcommand{\R}{\mathbb{R}}$
    $\newcommand{\Q}{\mathbb{Q}}$
    $\newcommand{\Z}{\mathbb{Z}}$
    $\newcommand{\N}{\mathbb{N}}$
    $\newcommand{\C}{\mathbb{C}}$
    $\newcommand{\P}{\mathbb{P}}$
    $\newcommand{\F}{\mathbb{F}}$
    $\newcommand{\L}{\mathcal{L}}$
    $\newcommand{\spa}[1]{\text{span}(#1)}$
    $\newcommand{\dist}[1]{\text{dist}(#1)}$
    $\newcommand{\max}[1]{\text{max}(#1)}$
    $\newcommand{\min}[1]{\text{min}(#1)}$
    $\newcommand{\supr}[1]{\text{sup}(#1)}$
    $\newcommand{\infi}[1]{\text{inf}(#1)}$
    $\newcommand{\argmax}[1]{\underset{#1}{\text{argmax }}}$
    $\newcommand{\argmin}[1]{\underset{#1}{\text{argmin }}}$
    $\newcommand{\set}[1]{\left\{#1\right\}}$
    $\newcommand{\emptyset}{\varnothing}$
    $\newcommand{\tilde}{\text{~}}$
    $\newcommand{\otherwise}{\text{ otherwise }}$
    $\newcommand{\if}{\text{ if }}$
    $\newcommand{\proj}{\text{proj}}$
    $\newcommand{\union}{\cup}$
    $\newcommand{\intercept}{\cap}$
    $\newcommand{\abs}[1]{\left| #1 \right|}$
    $\newcommand{\norm}[1]{\left\lVert#1\right\rVert}$
    $\newcommand{\pare}[1]{\left(#1\right)}$
    $\newcommand{\brac}[1]{\left[#1\right]}$
    $\newcommand{\t}[1]{\text{ #1 }}$
    $\newcommand{\head}{\text H}$
    $\newcommand{\tail}{\text T}$
    $\newcommand{\d}{\text d}$
    $\newcommand{\limu}[2]{\underset{#1 \to #2}\lim}$
    $\newcommand{\der}[2]{\frac{\d #1}{\d #2}}$
    $\newcommand{\derw}[2]{\frac{\d #1^2}{\d^2 #2}}$
    $\newcommand{\pder}[2]{\frac{\partial #1}{\partial #2}}$
    $\newcommand{\pderw}[2]{\frac{\partial^2 #1}{\partial #2^2}}$
    $\newcommand{\pderws}[3]{\frac{\partial^2 #1}{\partial #2 \partial #3}}$
    $\newcommand{\inv}[1]{{#1}^{-1}}$
    $\newcommand{\inner}[2]{\langle #1, #2 \rangle}$
    $\newcommand{\nullity}[1]{\text{nullity}(#1)}$
    $\newcommand{\rank}[1]{\text{rank }#1}$
    $\newcommand{\nullspace}[1]{\mathcal{N}\pare{#1}}$
    $\newcommand{\range}[1]{\mathcal{R}\pare{#1}}$
    $\newcommand{\var}[1]{\text{var}(#1)}$
    $\newcommand{\tr}[1]{\text{tr}(#1)}$
    $\newcommand{\oto}{\text{ one-to-one }}$
    $\newcommand{\ot}{\text{ onto }}$
    $\newcommand{\ceil}[1]{\lceil#1\rceil}$
    $\newcommand{\floor}[1]{\lfloor#1\rfloor}$
    $\newcommand{\Re}[1]{\text{Re}(#1)}$
    $\newcommand{\Im}[1]{\text{Im}(#1)}$
    $\newcommand{\dom}[1]{\text{dom}(#1)}$
    $\newcommand{\fnext}[1]{\overset{\sim}{#1}}$
    $\newcommand{\transpose}[1]{{#1}^{\text{T}}}$
    $\newcommand{\b}[1]{\boldsymbol{#1}}$
    $\newcommand{\None}[1]{}$
    $\newcommand{\Vcw}[2]{\begin{bmatrix} #1 \br #2 \end{bmatrix}}$
    $\newcommand{\Vce}[3]{\begin{bmatrix} #1 \br #2 \br #3 \end{bmatrix}}$
    $\newcommand{\Vcr}[4]{\begin{bmatrix} #1 \br #2 \br #3 \br #4 \end{bmatrix}}$
    $\newcommand{\Vct}[5]{\begin{bmatrix} #1 \br #2 \br #3 \br #4 \br #5 \end{bmatrix}}$
    $\newcommand{\Vcy}[6]{\begin{bmatrix} #1 \br #2 \br #3 \br #4 \br #5 \br #6 \end{bmatrix}}$
    $\newcommand{\Vcu}[7]{\begin{bmatrix} #1 \br #2 \br #3 \br #4 \br #5 \br #6 \br #7 \end{bmatrix}}$
    $\newcommand{\vcw}[2]{\begin{matrix} #1 \br #2 \end{matrix}}$
    $\newcommand{\vce}[3]{\begin{matrix} #1 \br #2 \br #3 \end{matrix}}$
    $\newcommand{\vcr}[4]{\begin{matrix} #1 \br #2 \br #3 \br #4 \end{matrix}}$
    $\newcommand{\vct}[5]{\begin{matrix} #1 \br #2 \br #3 \br #4 \br #5 \end{matrix}}$
    $\newcommand{\vcy}[6]{\begin{matrix} #1 \br #2 \br #3 \br #4 \br #5 \br #6 \end{matrix}}$
    $\newcommand{\vcu}[7]{\begin{matrix} #1 \br #2 \br #3 \br #4 \br #5 \br #6 \br #7 \end{matrix}}$
    $\newcommand{\Mqw}[2]{\begin{bmatrix} #1 & #2 \end{bmatrix}}$
    $\newcommand{\Mqe}[3]{\begin{bmatrix} #1 & #2 & #3 \end{bmatrix}}$
    $\newcommand{\Mqr}[4]{\begin{bmatrix} #1 & #2 & #3 & #4 \end{bmatrix}}$
    $\newcommand{\Mqt}[5]{\begin{bmatrix} #1 & #2 & #3 & #4 & #5 \end{bmatrix}}$
    $\newcommand{\Mwq}[2]{\begin{bmatrix} #1 \br #2 \end{bmatrix}}$
    $\newcommand{\Meq}[3]{\begin{bmatrix} #1 \br #2 \br #3 \end{bmatrix}}$
    $\newcommand{\Mrq}[4]{\begin{bmatrix} #1 \br #2 \br #3 \br #4 \end{bmatrix}}$
    $\newcommand{\Mtq}[5]{\begin{bmatrix} #1 \br #2 \br #3 \br #4 \br #5 \end{bmatrix}}$
    $\newcommand{\Mqw}[2]{\begin{bmatrix} #1 & #2 \end{bmatrix}}$
    $\newcommand{\Mwq}[2]{\begin{bmatrix} #1 \br #2 \end{bmatrix}}$
    $\newcommand{\Mww}[4]{\begin{bmatrix} #1 & #2 \br #3 & #4 \end{bmatrix}}$
    $\newcommand{\Mqe}[3]{\begin{bmatrix} #1 & #2 & #3 \end{bmatrix}}$
    $\newcommand{\Meq}[3]{\begin{bmatrix} #1 \br #2 \br #3 \end{bmatrix}}$
    $\newcommand{\Mwe}[6]{\begin{bmatrix} #1 & #2 & #3\br #4 & #5 & #6 \end{bmatrix}}$
    $\newcommand{\Mew}[6]{\begin{bmatrix} #1 & #2 \br #3 & #4 \br #5 & #6 \end{bmatrix}}$
    $\newcommand{\Mee}[9]{\begin{bmatrix} #1 & #2 & #3 \br #4 & #5 & #6 \br #7 & #8 & #9 \end{bmatrix}}$
  {{< /raw >}}
</div>

{{% definition name="Derived distribution" status="" %}}

Let $X$ be a continuous random variable and $h: \R \to \R$ be a function.
Want to determine the **derived distribution** $y = g(X)$.

We first calculate the CDF $F\_y $ of $Y $ using the formula

$$F\_Y(y) = \int\_{ \set{ x \in \R : g(x) \leq y }} f\_X(x) \d x $$

Then we differentiate to obtain the PDF of $Y$:

$$f\_Y(y) = \der{ F\_Y }{ y } (y)$$

{{% /definition %}}

{{% example name="" %}}

$X \tilde \text{Uniform}(-1, 1], Y= X^3.$ Find the distribution of $Y$.

$f\_X(x) = \begin{cases}
  \frac{ 1 }{ 2 }, x \in (-1, 1] \br
  0, x \not \in (-1, 1]
\end{cases}$

Step 1. find the CDF of $Y$.

$\begin{align}
  F\_Y(y) =& \int\_\set{ x: x^3 \leq y } f\_X(x) \d x \br
  =& \int\_{ -\infty }^{ \sqrt[ 3 ]{y}} f\_X(x) \d x \br
  =& \begin{cases}
  0& y < -1 \br
  \frac{ 1 }{ 2 } \sqrt[ 3 ]{ y } + \frac{ 1 }{ 2 } & y \in (-1, 1] \br
  1 & y > 1
  \end{cases}
\end{align}$

Step 2. Differentiate.

$\der{ }{ y } F\_Y(y) = \begin{cases}
\frac{ 1 }{ 2 } \abs{ \frac{ 1 }{ 3 } y ^{ - \frac{ 2 }{ 3 }}}=\frac{ 1 }{ 6 } y ^{ - \frac{ 2 }{ 3 }} & y \in (-1, 1] \br
0 & y \not \in (-1, 1]
\end{cases}$
{{% /example %}}

{{% remarks name="Monotonic" %}}

$f: I \to J. I, J \subseteq \R $.

$f$ is **strictly increasing** if $f(x) < f(y) , \forall x < y$.

$f$ is **strictly decreasing** if $f(x) > f(y) , \forall x < y $.

$f$ is **strictly monotonic** if it is either strictly increasing or strictly decreasing.

{{% /remarks %}}

{{% theorem name="derived distribution of monotonic function" index="" status="" %}}

Let $X$ be a continuous random variable such that $F\_X $ is differentiable.

Let $I, J $ be open intervals in $\R $, $g: I \to J $ be a strictly monotonic differentiable function with the range $g(I) = J$.

Assume further that $g'(x) \neq 0, \forall x \in I$, and $h: J \to I$ be the inverse of $g$.

Assume $h$ is differentiable. Then, the PDF of $Y$ in the region where $f\_Y(y) > 0$ is given by

$$f\_Y(y) = f\_X(h(y)) \abs{h'(y)} = f\_X(h(y)) \frac{ 1 }{ \abs{ g'(h(y))}}, \forall y \in J$$

{{% remarks name="" %}}

If $g: I \to J$ is strictly monotonic and subjective, then

exists the inverse function $h: J \to I $ such that

$$g(h(y))  = y, y \in J$$

By chain rule, we get

$$g'(h(y)) h'(y) = 1, y \in J$$

and therefore

$$h'(y) = \frac{ 1 }{ g'(h(y))} $$

{{% /remarks %}}

{{% /theorem %}}

{{% note name="" %}}

$F\_Y(y) = P(Y \leq y) = P(g(X) \leq y) = P(X \leq h(y))$, if $g$ is increasing.

$F\_Y(y) = P(Y \leq y) = P(g(X) \leq y) = P(X \geq h(y))$, if $g$ is decreasing.

If $g$ is increasing, $F\_Y(y)=\int\_{-\infty}^{h(y)}f\_X(x)\d x=F\_X(h(y))$.

If $g$ is decreasing, $F\_Y(y)= 1 - F\_X(h(y))$.

$f\_Y(y) = \der{  }{ y } (1- F\_X(h(y))) = - f\_X(h(y))h'(y)$.

{{% /note %}}

{{% example name="" %}}

$T\_A \tilde \text{Exponential}(\lambda), T\_B \tilde \text{Exponential}(\mu). \lambda, \mu > 0.$ Suppose $T\_A, T\_B$ are independent. $X = \max{ T\_A, T\_B }, Y = \min{ T\_A, T\_B }$. Want to know $F\_X, F\_Y $.

$\begin{align\*}
F\_X(y)=& P(\max{ T\_A, T\_B } \leq y) \br
=& P(T\_A \leq y, T\_B \leq y) \br
=& P(T\_A \leq y) P(T\_B \leq y) \br
=& F\_{T\_A}(y)F\_{T\_B}(y) \br
=& (1 - e^{- \lambda y})(1 - e^{ - \mu y })
\end{align\*}$

$f\_X(y) = \der{  }{ y }F\_X(y) $

$\begin{align\*}
&P(\min{ T\_A, T\_B } \leq y) \br
=& 1 - P(\min{ T\_A, T\_B } \geq y) \br
=& 1 - P(T\_A \geq y, T\_A \geq y) \br
=& 1 - P (T\_A \geq y) P (T\_B \geq y) \br
=& 1 - (1 - F\_{T\_A}(y))(1 - F\_{T\_B}(y)) \br
=& \begin{cases}
  1 - e^{-y \lambda}e^{-y \mu} = 1 - e ^{- (\lambda + \mu)y}, y \geq 0
\end{cases} 
\end{align\*}$

Note, $Min (T\_A, T\_B) ~ Exponential (\lambda + \mu)$

$E(X) = E(T\_A + T\_B - \min{ T\_A, T\_B }) = \frac{ 1 }{ \lambda } + \frac{ 1 }{ \mu } - \frac{ 1 }{ \lambda + \mu }$

$E(Y) = \frac{ 1 }{ \lambda + \mu } $


$X = \max{ T\_A, T\_B }$

$Y = \min{ T\_A, T\_B } $

$T\_A - T\_B - independent $

$F\_Y(y) = \iint\_{ \set{(a, b): \min{(a, b)} \leq y }} f\_{T\_AT\_B}(a, b) \d a \d b  = \iint\_{ \set{(a, b): \min{(a, b)} \leq y }}f\_{T\_A}(a) f\_{T\_B}(b) \d a \d  b$

$\begin{cases}
F\_Y(y) &= P(\min{ T\_A T\_B } \leq y)  = 1 - P(\min{  T\_A, T\_B } \geq y) \br
&= 1 - P(T\_A \geq y, T\_B \geq y) = 1- P(T\_A \geq y)P(T\_B \geq y) \br
&= 1 - (1 - F\_{T\_A}(y))(1 - F\_{T\_B}(y))
\end{cases}$ 

{{% /example %}}

{{% example name="" %}}

Suppose $X,Y $ are two independent integratable random variable. Then the probability mass function of $x + y $ is given by 

for $t \in \Z,$

$\begin{align\*}
P\_{X+Y}(t)  \br
=& P(X+Y = t)  \br
=& (TPF) \sum\_{ x \in \Z } P(X = x) P(X + Y = t | X = x)  \br
=& \sum\_{ x \in \Z } P(X = x) P(Y = t - x | X = x)  \br
=& \sum\_{ x \in \Z } P(X = x) P(Y = t - x)  \br
=& \sum\_{ x \in \Z } P\_X(x)P\_Y(t- x)
\end{align\*}$


{{% /example %}}

{{% definition name="Convolution over integers" status="" %}}

For $f, g: \Z \to \R $, we define the convolution of $f$ and $g$ denoted by $f \* g $, by the formular $f * g(t) =  \sum\_{  x \in \Z } f(x)g(t - x), t \in \Z $

Note that, in the example, $P\_{X+Y} (t) = P\_{X} * P\_Y(t)$

{{% /definition %}}

{{% definition name=" Convolution on the real line" status="" %}}

If $f, g: \R \to \R $, then their convolution $f * g$ is defined by $f * g (t) = \int\_{ x \in \R } f(x) g(t - x) \d x, t \in \R $

{{% /definition %}}


{{% theorem name="" index="" status="" %}}

Let $X, Y $ be two independent random variable, such that$F\_{X+Y}(t)$ is differentiable $\forall t \in R$. Then

$$f\_{X+Y}(t) = f\_X *f\_Y(t) \forall t \in \R $$

{{% proof index="" method="" %}}

$F\_{X+Y}(t) = P(X +Y \leq t) = \iint\_{ \set{(x, y) \in \R, x + y \leq t }} f\_{X, Y}(x, y) \d x \d  y == \iint\_{ \set{(x, y) \in \R, x + y \leq t }} f\_X(x)f\_Y(y) \d x \d y = \int\_{ x \in \R } \int\_{ -\infty }^{ t - x } f\_X(x) f\_Y(y) \d y \d x$

$f\_{X+Y}(t) = \der{  }{ t } F\_{X+Y} (t) = \der{  }{ t } \int\_{ x \in \R } \int\_{ -\infty }^{ t - x } f\_X(x) f\_Y(y) \d y \d x = \int\_{ x \in \R } f\_X(x) \der{  }{ t } \int\_{ -\infty }^{ t - x } f\_Y(y) \d y \d x=  \int\_{ x \in \R } f\_X(x) f\_Y(t - x) \der{  }{ t }(t - x) \d x =  \int\_{ x \in \R } f\_X(x)  f\_Y(t - x) \d x  = f\_X*f\_Y(t)$

{{% /proof %}}

{{% /theorem %}}

{{% definition name="Convolution" status="" %}}

**(discrete case)**

Let $Z = X + Y $, where $X$ and $Y$ are independent integer-valued random variables with PMFs $p\_X $ and $p\_Y $, respectively. Then, for any integer $z $,

$$\begin{align\*}
  p\_Z(z) &= P(X + Y = z) \br
  &= \sum\_{ \set{(x, y) | x + y = z }} P(X = x, Y = y) \br
  &= \sum\_{ x } P(X = x, Y = z - x) \br
  &= \sum\_{ x } p\_X(x)p\_Y(z - x)
\end{align\*}$$

The resulting PMF $p\_z $ is called the **convolution** of the PMFs of $X  $ and $Y $.

**(continuous case)**

Suppose now that $X $ and $Y $ are independent continuous random variables with PDFs $f\_X$ and $f\_Y $, respectively. Then, to find the PDF of $Z $, we first note that

$$\begin{align\*}
  P(Z \leq z | X = x) =& P(X + Y \leq z | X = x) \br
  =& P(x + Y \leq z | X = x) \br
  =& P(x + Y \leq z) \br
  =& P(Y \leq z - x)
\end{align\*}$$

By differentiating both sides with respect to $z$, we see that $f\_{Z|X}(z|x) = f\_Y(z - x) $. Using the multiplication rule, we have


$$\begin{align\*}
f\_{X, Z}(x, z)  =& f\_X(x) f\_{Z|X}(z|x) \br
=& f\_X(x)f\_Y(z- x)
\end{align\*}$$

Then,


$$\begin{align\*}
f\_Z(z) =& \int\_{ -\infty }^{ +\infty } f\_{X, Z} (x, z) \d x \br
=& \int\_{ -\infty }^{ +\infty } f\_X(x) f\_Y(z - x) \d x
\end{align\*}$$



{{% /definition %}}

