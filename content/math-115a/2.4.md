---
title: "Invertibility and Isomprphisms"
date: 2018-07-18T11:03:48+08:00
author: "Jim Zenn"
volumes: ["MATH 115A"]
layout: "note"
issue: 2.4


---

Linear transformation, range, kernel (null space), range (image),

<!--more-->

<div class="latex-macros">
  {{< raw >}}
    $\newcommand{\br}{\\}$

    $\newcommand{\R}{\mathbb{R}}$
    $\newcommand{\Q}{\mathbb{Q}}$
    $\newcommand{\Z}{\mathbb{Z}}$
    $\newcommand{\N}{\mathbb{N}}$
    $\newcommand{\C}{\mathbb{C}}$
    $\newcommand{\P}{\mathbb{P}}$
    $\newcommand{\F}{\mathbb{F}}$
    $\newcommand{\L}{\mathcal{L}}$
    $\newcommand{\spa}[1]{\text{span}(#1)}$
    $\newcommand{\set}[1]{\{#1\}}$
    $\newcommand{\emptyset}{\varnothing}$
    $\newcommand{\otherwise}{\text{otherwise}}$
    $\newcommand{\if}{\text{if}}$
    $\newcommand{\union}{\cup}$
    $\newcommand{\intercept}{\cap}$
    $\newcommand{\abs}[1]{|#1|}$
    $\newcommand{\pare}[1]{\left\(#1\right\)}$
    $\newcommand{\t}[1]{\text{#1}}$ $\newcommand{\inv}[1]{{#1}^{-1}}$ $\newcommand{\head}{\text H}$
    $\newcommand{\tail}{\text T}$
    $\newcommand{\nullity}[1]{\text{nullity}(#1)}$
    $\newcommand{\rank}[1]{\text{rank}(#1)}$
    $\newcommand{\oto}{\text{ one-to-one }}$
    $\newcommand{\ot}{\text{ onto }}$


    $\newcommand{\Vcw}[2]{\begin{pmatrix} #1 \br #2 \end{pmatrix}}$
    $\newcommand{\Vce}[3]{\begin{pmatrix} #1 \br #2 \br #3 \end{pmatrix}}$
    $\newcommand{\Vcr}[4]{\begin{pmatrix} #1 \br #2 \br #3 \br #4 \end{pmatrix}}$
    $\newcommand{\Vct}[5]{\begin{pmatrix} #1 \br #2 \br #3 \br #4 \br #5 \end{pmatrix}}$
    $\newcommand{\Vcy}[6]{\begin{pmatrix} #1 \br #2 \br #3 \br #4 \br #5 \br #6 \end{pmatrix}}$
    $\newcommand{\Vcu}[7]{\begin{pmatrix} #1 \br #2 \br #3 \br #4 \br #5 \br #6 \br #7 \end{pmatrix}}$

    $\newcommand{\Mqw}[2]{\begin{bmatrix} #1 & #2 \end{bmatrix}}$
    $\newcommand{\Mqe}[3]{\begin{bmatrix} #1 & #2 & #3 \end{bmatrix}}$
    $\newcommand{\Mqr}[4]{\begin{bmatrix} #1 & #2 & #3 & #4 \end{bmatrix}}$
    $\newcommand{\Mqt}[5]{\begin{bmatrix} #1 & #2 & #3 & #4 & #5 \end{bmatrix}}$

    $\newcommand{\Mwq}[2]{\begin{bmatrix} #1 \br #2 \end{bmatrix}}$
    $\newcommand{\Meq}[3]{\begin{bmatrix} #1 \br #2 \br #3 \end{bmatrix}}$
    $\newcommand{\Mrq}[4]{\begin{bmatrix} #1 \br #2 \br #3 \br #4 \end{bmatrix}}$
    $\newcommand{\Mtq}[5]{\begin{bmatrix} #1 \br #2 \br #3 \br #4 \br #5 \end{bmatrix}}$

    $\newcommand{\Mqw}[2]{\begin{bmatrix} #1 & #2 \end{bmatrix}}$
    $\newcommand{\Mwq}[2]{\begin{bmatrix} #1 \br #2 \end{bmatrix}}$
    $\newcommand{\Mww}[4]{\begin{bmatrix} #1 & #2 \br #3 & #4 \end{bmatrix}}$
    $\newcommand{\Mqe}[3]{\begin{bmatrix} #1 & #2 & #3 \end{bmatrix}}$
    $\newcommand{\Meq}[3]{\begin{bmatrix} #1 \br #2 \br #3 \end{bmatrix}}$
    $\newcommand{\Mwe}[6]{\begin{bmatrix} #1 & #2 & #3\br #4 & #5 & #6 \end{bmatrix}}$
    $\newcommand{\Mew}[6]{\begin{bmatrix} #1 & #2 \br #3 & #4 \br #5 & #6 \end{bmatrix}}$
    $\newcommand{\Mee}[9]{\begin{bmatrix} #1 & #2 & #3 \br #4 & #5 & #6 \br #7 & #8 & #9 \end{bmatrix}}$
  {{< /raw >}}
</div>

{{% definition name="" %}}

A linear transformation $T: V \to W$ is called invertible if

$\exists$ a function $U: W \to V$ s.t. $TU = I\_W$ and $UT = I\_V$.

{{% /definition %}}

{{% remarks name="" %}}

1. $T$ is invertible $\iff T$ is bijective
2. Let $T\_1: V \to W, T\_2: W \to V$ are both invertible, then $T\_2T\_1$ is also invertible and $(T\_2T\_1)^{-1} = (T\_1)^{-1}(T\_2)^{-1}$
3. If $T: V \to V/F$ is invertible, then $(T^{-1})^{-1} = T$
4. A linear transformation $T:V \to W$ is invertible $\iff$ $N(T) = {0}$ and $R(T)= W$

{{% /remarks %}}

{{% theorem name="" index="" %}}

If $T:V \to W$ is an invertible linear transformation, and $T^{-1}: W \to V$  is its inverse, then $T^{-1}$ is also linear.

{{% proof index="" name="" %}}
$w\_1, w\_2 \in W, a \in F$

$\inv{T}(aw\_1 + w\_2) = $

$\because T: V \to W$ is invertible, $T$ is bijective, in particle, subjective.

$\therefore v\_1, v\_2 \in V$ s.t.

$T(v\_1)= w\_1  \implies aw\_1 = aT(v\_1) = T(av\_1)$
$T(v\_2)= w\_2  \implies aw\_1 +w\_2 = T(av\_1) + T(v\_2) = T(av\_1 + v\_2)$

$\inv{T}(aw\_1 + w\_2) = \inv{T}(T (av\_1 + v\_2) = av\_1 + v\_2$

$\because T$ is bijective and $T(u\_1) = w\_1$ and $T(v\_2) = w\_2$

We have $v\_1 = \inv{T}(w\_1), v\_2 = \inv{T}(w\_2)$

{{% /proof %}}

{{% /theorem %}}



{{% theorem name="" index="" %}}

Let $T: V \to W$ be an invertible linear transformation. Then $\dim V $ is finite $\iff \dim W $ is finite. Moreover, when they are finite $\dim V = \dim W $

{{% proof index="" name="" %}}

$T: V \to W$ invertible

assume that $\dim V = n$ finite. Let $\beta = \set{ x\_1, x\_2, ..., x\_{n}}$ be a basis of $V$.


Then $R(T) = \spa{T(\beta)} $

$T: V \to W, invertible \implies is subjective. \therefore R(T) = W$

$\therefore W= span(\set{ T(x\_1), T(x\_2), ..., T(x\_{})})$

$\therefore \dim W $ is finite is finite

Furthermore, since $ T $ is also injective and $\beta$ is linearly independent in $V, T(\beta) $ is linearly independent in $W$.

Thus from (1)
it follows that $ T(\beta)$  is a basis of $ W $.

$\therefore \dim W = n = \dim V$

Assume that $ W $ ifs finite dimensional. $ T $ is invertible, $T: W \to V $ also an invertible linear transformation.

Switching the role of V and W in the previous proof we see that $\dim V$ is also finite.

{{% /proof %}}

{{% /theorem %}}


{{% theorem name="" index="" %}}

let $T: V \to W$ and $V, W$ are finite dimensional. Let $\beta$ and $\gamma$ are ordered basis of $V$ and $W$, respectively.
Then T is invertible $\iff [T]^ \gamma \_ \beta $ is a invertible matrix.

Moreover, in this case $[T^{-1}]^ \beta \_ \gamma = \inv{[T]^ \gamma \_ \beta}$

{{% proof index="" name="" %}}

Assume that $ T $ is invertible.

$\therefore$ by previous thm, $\dim V = \dim W = n $

$\therefore [T]^\gamma\_\beta$ is a $ n \times n $ matrix.

Since $ T: V \to W $ is invertible.

$\exists U: V \to V s.t. UT = I\_V$ s.t.

$UT = I\_V$

$TU = I\_W$

From (i) and (ii) it  follows that $[ T ]^{ \gamma }\_{ \beta }$ is an invertible matrix. and $\inv{ [ T ]^{ \gamma }\_{ \beta }} = [ U ]^{ \beta }\_{ gamma }$(iii)

{{% /proof %}}

{{% proof index="" name="" %}}

Assume that $ [ T ]^{ \gamma }\_{ \beta } $ is an $n \times n $ invertible matrix.

let $A = [ T ]^{ \gamma }\_{ \beta }$

$AB = I\_n = [ T ]^{ \gamma }\_{ \beta } [ U ]^{ \beta }\_{ \gamma } = [ I\_w ]\_{ \gamma } $

{{% /proof %}}

{{% /theorem %}}

{{% theorem name="" index="" %}}

$\exists$ a matrix $B\_{n \times n}$ s.t. $AB = BA = I\_n $

let $B = (b\_{ij})\_{n \times n}$

let $\beta = \set{ v\_1, v\_2, ..., v\_{ n }}$ and $\gamma = \set{ w\_1, w\_2, ..., w\_{ n }}$ are ordered basis as given


Then by previous these exists a unique linear transformation $V: W \to V s.t. $

$$U(w\_j) = \sum\_{ i=1 }^{ n }b\_{ij}v\_i$$

$$ U(w\_j) = \sum\_{ i=1 }^{ n } b\_{ij}v\_i $$

{{% /theorem %}}

{{% remarks name="" %}}

$[T]^{\beta}\_{\gamma}[U]^{\gamma}\_{\beta} = I\_n$(i)

$[U]^{\gamma}\_{\beta}[T]^{\beta}\_{\gamma} = I\_n$(ii)

$\implies TU = I\_w$

Similarly, $BA = I\_n \implies UT = I\_w$

$\therefore$ we have $TU = I\_v, UT = I\_w$

i.e. $T$ is invertible.

{{% /remarks %}}


{{% definition name="Isomorphism" %}}

A linear transformation $T:V \to W$ is called an isomorphism T is invertible and is this  case we say that $ V $ is isomorphic to $W $.

{{% /definition %}}

{{% remarks name="" %}}

If $T$ is an isomorphism, then T is invertible $\implies \inv{ T }: W \to V $ is an invertible linear transformation $\implies \inv{ T }$ is also an isomorphism.

In particular, if $T: V \to W$ is an isomorphism we say $ V $ and $ W $ are isomorphic to each other and we write $V \cong W $.

{{% /remarks %}}


{{% theorem name="" index="" %}}

$T: V \to W, V, W$ two vectors, assume that $V$ and $W$ are both finite dimensional.

Then $T$ is an isomorphism. $\iff  \dim V = \dim W $

{{% proof index="" name="" %}}

**Assume** $V \cong W$.

let $ T: V \to W $ be such an isomorphism.

let $\beta = \set{ v\_1, v\_2, ..., v\_{ n }}$ be a basis of $V $

Then $ T(\beta) $ is a basis of $ W $. $\dim V  = n = \dim W$.

**Assume** $\dim V = \dim W = n $

Let $\beta = \set{ v\_1, v\_2, ..., v\_{ n }}  and \gamma = \set{ w\_1, w\_2, ..., w\_{ n }} $ be two basis of $ V $ and $ W $ respecting.

Then $\exists$ a unique linear transformation $ T: V \to W $ s.t.

$T(v\_i) = w\_i, \forall i = 1, 2, ..., n $.

Then $\exists$ unique linear transformation $T: V \to W$ s.t. $ T(v\_i) = w\_i  \forall i = 1, 2, ..., n$

$\begin{align\*}
R(T) &= span(\set{ T(v\_1), T(v\_2), ..., T(v\_{ n })})
&= \spa{ w\_1, w\_2, ..., w\_{ n }}
&= W
\end{align*}$

$\therefore \rank{ T } = \dim R(T)  = \dim W = n$

In particular, $ T $ is surjective.

Now by dimension theorem.

$\nullity{ T } = \dim V - \rank{ T } = n -n = 0$

$\implies N(T) = \set{ 0 }$

$\implies T is injective $

$\implies T is bijective \implies T is an isomorphism$.



{{% /proof %}}

{{% /theorem %}}

{{% corollary name="" index="" %}}
If $V$ is a vector space over field $F$ and $\dim V = n$
Then $V/F \cong F^n/F, (a\_1, \_2, ..., \_{ n }) \in F^n$

{{% /corollary %}}

{{% theorem name="" index="" %}}

$V/F, W/F$

$\dim V = n, \dim W = n$

$\L(V, W) \cong M\_{m \times n}(F)$

{{% proof index="" name="" %}}

Let $\beta = \set{ v\_1, v\_2, ..., v\_{ n }}$ and $\gamma = \set{ w\_1, w\_2, ..., w\_{ m }} $ be two fixed ordered basis of $ V $ and $W$, respectively.

Recall that: <br>
a function is bijective $\iff $ every point in the codomain has exactly one pre-image.

define a map $\Phi: \L(V, W) \to M\_{m \times n}(F) $ i.e. $\Phi(T) = [ T ]^{ \gamma }\_{ \beta }$

but $A \in M\_{m \times n}(F)$.

We need to find $T$ s.t. $[ T ]^{ \gamma }\_{ \beta} = A$

Let $A = (a\_{ij})\_{m \times n}$.

By a previous there exists a unique linear transformation $ T: V \to W $ s.t. $T(v\_{ij}) = \sum\_{ i=1 }^{ m } a\_{ij}w\_i$.

But thm $ [ T ]^{ \gamma }\_{ \beta } = A $ i.e. $\Phi(T) = [ T ]^{ \gamma }\_{ \beta } = A $

and $ T $ is unique  pre-image of $A$

$\implies \Phi$ is bijective

$\implies \Phi$ is an isomorphism

{{% /proof %}}

{{% /theorem %}}

{{% corollary name="" index="" %}}

If $\dim V = n$ and $\dim W = m $, then $\dim \L(v,m) = mn $.

{{% proof index="" name="" %}}

By the previous theorem

$\L(V, W) \cong M\_{m \times n}(F)$

$\dim M\_{m \times n} (F) = mn$

$\dim \L(V, W)  = mn$


{{% /proof %}}

{{% /corollary %}}
